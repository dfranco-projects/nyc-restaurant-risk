# NYC Restaurant Inspection Risk Classification

This project regards the development of a multiclass classification model to predict health **risk categories** (Low, Moderate, High) for restaurants in New York City based on inspection and violation data. It also integrates **generative AI** to produce mock public health alerts.

## ğŸ” Problem Overview

The NYC Health Department inspects restaurants regularly and assigns them a risk category based on observed violations. Early identification of high-risk establishments can help prioritize enforcement and protect public health.

## ğŸ“‚ Project Structure

```bash
nyc-restaurant-risk/
â”‚
â”œâ”€â”€ data/                   # raw and processed data
â”‚   â”œâ”€â”€ raw/                # raw dataset
â”‚   â””â”€â”€ processed/          # cleaned + split datasets
â”‚
â”œâ”€â”€ notebooks/              # jupyter workflows
â”‚   â”œâ”€â”€ 01_data_understanding.ipynb
â”‚   â”œâ”€â”€ 02_preprocessing_eda.ipynb
â”‚   â”œâ”€â”€ 03_feature_eng_modeling.ipynb
â”‚   â”œâ”€â”€ 04_evaluation_visualization.ipynb
â”‚   â””â”€â”€ 05_genai_alerts.ipynb
â”‚
â”œâ”€â”€ src/                     # utility/reusable functions
â”‚   â”œâ”€â”€ data_utils.py
â”‚   â”œâ”€â”€ eda_utils.py
â”‚   â”œâ”€â”€ modeling.py
â”‚   â””â”€â”€ genai.py
â”‚
â”œâ”€â”€ model/                  # final model and metrics
â”œâ”€â”€ plots/                  # Confusion matrix, maps, EDA figures
â”œâ”€â”€ slides/                 # Final presentation
â”œâ”€â”€ README.md               # project overview
â””â”€â”€ requirements.txt        # python dependencies
```


## âš™ï¸ Tech Stack

- Python 3.10+
- Jupyter Notebooks
- Scikit-learn, XGBoost, LightGBM
- Pandas, NumPy
- Seaborn, Matplotlib, Plotly
- GeoPandas (for maps)
- OpenAI API (for GenAI task)

## ğŸš€ How to Run Locally

1. **Clone the repo**

```bash
git clone https://github.com/dfranco-projects/nyc-restaurant-risk.git
cd nyc-restaurant-risk
```

2. **Create virtual environment**

```bash
python3 -m venv .venv
source .venv/bin/activate        # On Windows: .venv\Scripts\activate
```

3. **Install dependencies**

```bash
pip install -r requirements.txt
```

4. **Run notebooks in order**

Open Jupyter or VS Code and start with:

- `01_data_understanding.ipynb`
- `02_preprocessing_eda.ipynb`
- `03_feature_engineering.ipynb`
- `04_modeling.ipynb`
- `05_evaluation_visualization.ipynb`
- `06_genai_alerts.ipynb`

Each notebook builds on the previous step and produces artifacts (e.g., processed data, model outputs).

## ğŸ§  Bonus: Generative AI Alerts

In `06_genai_alerts.ipynb`, we use OpenAI's GPT to generate automated public health alerts based on borough-level trends in high-risk violations.

---

## ğŸ“ˆ Deliverables

- Clean, well-commented notebooks
- Model performance metrics (accuracy, macro-F1)
- Visualizations (EDA, confusion matrix, borough heatmaps)
- Presentation slide deck (5â€“7 slides)
- README with full reproducibility instructions

